2024.12.15
    ①构建变化信息作为变化类别的数据集— —A车出现、消失 B车出现、消失 C车出现、消失
    ②对卫星数据集进行实验
    ③对ChangeFormer-main  将Transformer Encoder  -->  Shunted Transformer Encoder
    	— —发现Attention模块中的num_heads有问题，更换__init__设置后可行了
    	— —换了以后输出的维度还是没能对齐，最后强制对齐
    	— —最后只换了一个Attention模块（主要区别也在于此SSA模块），能跑通，效果也不错（未可视化），但是指标是并没有提升
    	
2024.12.16😇️
    ①对BIT-master  将特征提取backbone由ResNet  -->  LSKNet
    	— —在更换backbone后可以跑通，但是由于没有预训练权重，所以指标为0
    	— —加载lsk_s_backbone_xxx.pth存在问题，怀疑与源码规定的load_state_dict格式不符
    ②思考：那么在ChangeFomer前面加入CNN提取特征是否可行？
    
2024.12.17
    ①跑通SNUNet并研读论文
    ②思考其改进       (未完成！！！)
    
2024.12.18🙂️
    ①在昨晚和pmy师兄的讨论中发现，不加载预训练权重也可以跑通，于是今早上试了一下，确实是有指标的，只不过有点偏低
    	— —epoch=200  | acc: 0.96597 miou: 0.60798 mf1: 0.69148 iou_0: 0.96558 iou_1: 0.25038 F1_0: 0.98249 F1_1: 0.40048 precision_0: 0.96894 precision_1: 0.76841 recall_0: 0.99642 recall_1: 0.27081 |
    	— —epoch=300  | acc: 0.95853 miou: 0.65930 mf1: 0.75443 iou_0: 0.95754 iou_1: 0.36106 F1_0: 0.97831 F1_1: 0.53056 precision_0: 0.97141 precision_1: 0.62686 recall_0: 0.98530 recall_1: 0.45990 |
    	对比200与300   指标变化：acc pre ↓   miou mf1 recall ↑
   	— —get到师兄用了空洞卷积ASPP，这方面可以了解一下并尝试修改（！！！仅用于尝试与锻炼动手能力，本人不会用于知识剽窃！！！）
    ②同样，昨晚和zxw师兄讨论，get到RepVGG，今天尝试将特征提取backbone: LSKNet --> RepVGG
    ③需要联系双美师姐确认数据集格式的事情
    ④下午上课的时候可以研究一下BIT以及ChangeFormer的消融实验，弥补之前阅读的遗漏之处
    
2024.12.19😁️
    ①对BIT-maste  将backbone由ResNet --> Dilated Mutil-Scale Fusion Module (DMSFM)   <空洞卷积+多尺度融合>
    	— —简单的对齐了输入输出之后跑通了200epochs，指标如下：|  acc: 0.95314 miou: 0.62531 mf1: 0.71760 iou_0: 0.95219 iou_1: 0.29844 F1_0: 0.97551 F1_1: 0.45969 precision_0: 0.96783 precision_1: 0.55719 recall_0: 0.98331 recall_1: 0.39123   |   (使用的是上采样与通道调整方法)
    	— —修改方法为卷积与平均池化（实质：加了RELU），指标如下： |  acc: 0.95838 miou: 0.69074 mf1: 0.78699 iou_0: 0.95707 iou_1: 0.42441 F1_0: 0.97806 F1_1: 0.59591 precision_0: 0.97862 precision_1: 0.58968 recall_0: 0.97750 recall_1: 0.60228   |
    	— —在上述基础上，将batchsize 3-->8，指标如下： |  acc: 0.96468 miou: 0.73070 mf1: 0.82312 iou_0: 0.96339 iou_1: 0.49800 F1_0: 0.98135 F1_1: 0.66489 precision_0: 0.98318 precision_1: 0.64346 recall_0: 0.97954 recall_1: 0.68779  |
    	对比LSKNet(200epoch)，效果还是略好的，那么，到底是我简单粗暴的错还是代码输入输出的错？
    ②对BIT-master 将backbone由ResNet --> FADConv <频率自适应扩张卷积模块>
    	— —(使用AvgPool2d下采样)对齐了输入输出之后跑通了200epochs指标与LSKNet、DMSFM大同小异：|  acc: 0.96220 miou: 0.70780 mf1: 0.80259 iou_0: 0.96097 iou_1: 0.45464 F1_0: 0.98010 F1_1: 0.62509 precision_0: 0.97954 precision_1: 0.63181 recall_0: 0.98065 recall_1: 0.61851|  
    	— —(使用stride=4进行下采样)： 暂时未使用
    	— —在ResNet提取之后加上FADConv，是否有效呢？|  acc: 0.97140 miou: 0.77367 mf1: 0.85837 iou_0: 0.97024 iou_1: 0.57710 F1_0: 0.98490 F1_1: 0.73185 precision_0: 0.98737 precision_1: 0.70065 recall_0: 0.98243 recall_1: 0.76596   |
    	— —dcg建议我用在ResNet之前加上FADConv：！！！各方面指标均涨点了，不过这个涨点是对比BIT而言！！！（第一次涨点很开心，谢谢dcg😄️）
    	— —在ResNet的特征提取结束后+FADConv(x_8通道扩展)：
    	— —在ResNet的特征提取结束后+FADConv(output layers)：
    ③！！！对比之前ResNet发现，参数的设置确实有问题，batchsize 32 --> 8，小batchsize有助于提高！！！（目前num_workers仍为4，感觉不影响）
    ④尝试display attention map，红色表示较高的关注值，蓝色表示较低的值
    
2024.12.20🙂️
    ①通知周一去北京，即做好去北京的准备工作
    — —环境、代码、数据集
    ②是否：当前baseline已经不适合以SOTA为目标？
    ③对BIT-master 将backbone由ResNet --> swinTrans
    	— —FADConv+swinTrans：|  acc: 0.97237 miou: 0.76708 mf1: 0.85286 iou_0: 0.97135 iou_1: 0.56281 F1_0: 0.98547 F1_1: 0.72026 precision_0: 0.98385 precision_1: 0.74375 recall_0: 0.98709 recall_1: 0.69820   | （无预训练权重）
    	— —单独swinTrans：|  acc: 0.97104 miou: 0.76424 mf1: 0.85075 iou_0: 0.96994 iou_1: 0.55854 F1_0: 0.98474 F1_1: 0.71675 precision_0: 0.98491 precision_1: 0.71443 recall_0: 0.98457 recall_1: 0.71909   | （无预训练权重）
    	！！！说明FADConv还是有一定效果的！！！

2024.12.21🙃️
    ①对ChangeFormer 将Encoder --> swinTrans	（先弄清楚backbone的预训练加载流程与方法，包括BIT和ChangeFormer）
    	— —
    ②对BIT-master 将backbone由ResNet --> swinTrans
    	— —单独swinTrans：|  acc: 0.97024 miou: 0.76180 mf1: 0.84886 iou_0: 0.96909 iou_1: 0.55451 F1_0: 0.98430 F1_1: 0.71342 precision_0: 0.98532 precision_1: 0.70027 recall_0: 0.98329 recall_1: 0.72707   | （已加载预训练权重）
    ③目前解决了pretrain加载问题（效果待验证）
    — —有一定效果，但不能解决根本问题：|  acc: 0.94826 miou: 0.66251 mf1: 0.76082 iou_0: 0.94658 iou_1: 0.37844 F1_0: 0.97255 F1_1: 0.54909 precision_0: 0.97923 precision_1: 0.49380 recall_0: 0.96597 recall_1: 0.61831   |
    — —利用pretrain与FADConv+LSKNet：|  acc: 0.96494 miou: 0.69186 mf1: 0.78647 iou_0: 0.96402 iou_1: 0.41971 F1_0: 0.98168 F1_1: 0.59126 precision_0: 0.97349 precision_1: 0.72802 recall_0: 0.99002 recall_1: 0.49775   |  （对比纯LSKNet有提升）
    — —利用pretrain与LSKNet+FADConv：|  acc: 0.96954 miou: 0.73664 mf1: 0.82743 iou_0: 0.96856 iou_1: 0.50471 F1_0: 0.98403 F1_1: 0.67084 precision_0: 0.97923 precision_1: 0.74622 recall_0: 0.98888 recall_1: 0.60929   |  （提升显著）
    — —不加pretrain与LSKNet+FADConv：|  acc: 0.94439 miou: 0.51059 mf1: 0.55718 iou_0: 0.94413 iou_1: 0.07706 F1_0: 0.97126 F1_1: 0.14309 precision_0: 0.95304 precision_1: 0.33288 recall_0: 0.99019 recall_1: 0.09113   |  （非常垃圾）
        对比证明：预训练权重确实很重要，不过是否能够涨点或效果好，更重要的是backbone所提取到的特征和后处理网络(baseline)的可结合性

2025.0105🙃️
    ①发现之前用的数据集均为1024*1024，共600+  -->  实际应为 256*256，共  10000+
    	— —训练时间会显著增加，但是或许效果不错？
    	— —这或许是我一直不能完美复现ChangeFormer的原因吗？
    ②对承德1130数据进行处理
    	— —
    	
    	
2025.0106
    ①hq师兄北京反馈：
    	— —大图切分推理代码（！！！未找到 ！！！）  -->  应自己修改或选择调用
    	— —demo.py 直接把图片放缩至 256 * 256尺寸
    	— —任务：跑实验同步解决大图推理问题、验证是否overlap！！！
    ②尝试数据增强方法，略微提点：/datasets/data_utils.py   --  class CDDataAugmentation  Faulse --> True			？？？
    
2025.0209😶️
   ①整理近一个月的实验数据：
   	— —目前最有效的是SegFusion版本的改进,正在尝试更高水平的指标
   ②完成专利交底书中的第一、二部分：
   	— —本发明要解决的技术问题、详细介绍技术背景并描述与本发明最相近的实现方案     √
   	
2025.0210
    ①通过SegFusion网络已达到较好水平指标		-->  F1：91.462 IOU1：84.267
    	— —工作总结：1.input经过First_DoubleConv后送入SwinTransformer模块 --> 输出四个尺度的特征
    		    2.input经过最大池化（下采样）和DoubleConv后生成(B,64,128,128)尺度
    		    3.生成的5个尺度特征经过DAFM模块进行注意力增强
    		    4.送入decoder后经过MLP层处理后进行diff作差（emdbedding_dim设为256）
    		    5.对5个尺度的diff特征进行频域特征融合
    		    6.经过上采样后生成预测图
    ②完成专利交底书中的第三、四、五部分：
    	— —现有技术的缺点是什么？针对这些缺点，说明本发明的目的。
    	— —本发明技术方案的详细阐述，应该结合附图进行说明。
    	— —本发明的关键点和保护点是什么？
    ③***尝试将代码移植到OpenCD上***
    	— —查看是否涨点
    	
    	
2025.0219🙂️
    ①SegFusion网络     Epoch 400 -->  F1：91.483 IOU1：84.303
    ②***仍在探索OpenCD上的相关代码移植***
    	— —BIT ChangeFormer算法确实在OpenCD上有提高
    	— —！！！该框架训练时间较短！！！
    	— —但是SwinTransformer在该上面的效果不佳（最起码相同的Decoder时效果不如MIT-b0）
    	— —DeforTransformer的效果还行，有待验证（缺点：缺少fp16函数的情况下训练时间较长，但是其实5h也能接受）
    	— —尝试完全移植后的效果
    ③尝试在SwinTrans中加入频域方法作为引导
    	— —1024尺寸上效果不错，期待256上的结果（最起码不要掉点啊！！）
   ④构思无人机图像的数据集制作
   ⑤待缝合：
   	— —24. (ECCV2024)Agent-Attention
   	— —22. (ICCV 2023)Dysample_UP轻量化上采样	√
   	— —35. (ICIP2024)AFEBlock
   	— —39. (CVPR 2024) FADC频率自适应扩张卷积模块	√
   	
2025.0227
    ①尝试在多尺度频域特征融合后进行  通道、尺寸的对齐 --> 相加
    ②尝试在多尺度频域特征融合后进行  通道、尺寸的对齐 --> linear_fuse(cat后一起转换通道)
    ③尝试修改差异提取模块
    
2025.0228
    ①
